{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "34695867",
      "metadata": {
        "papermill": {
          "duration": 0.004574,
          "end_time": "2024-01-21T13:30:48.667159",
          "exception": false,
          "start_time": "2024-01-21T13:30:48.662585",
          "status": "completed"
        },
        "tags": [],
        "id": "34695867"
      },
      "source": [
        "## Basic Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24bfb8f7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-21T13:30:48.677692Z",
          "iopub.status.busy": "2024-01-21T13:30:48.677398Z",
          "iopub.status.idle": "2024-01-21T13:31:21.618930Z",
          "shell.execute_reply": "2024-01-21T13:31:21.617971Z"
        },
        "papermill": {
          "duration": 32.953276,
          "end_time": "2024-01-21T13:31:21.624863",
          "exception": false,
          "start_time": "2024-01-21T13:30:48.671587",
          "status": "completed"
        },
        "scrolled": true,
        "tags": [],
        "id": "24bfb8f7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import transformers\n",
        "import sklearn\n",
        "import os\n",
        "import gc\n",
        "import re\n",
        "import random\n",
        "import time\n",
        "import sys\n",
        "import optuna\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from accelerate import cpu_offload, dispatch_model\n",
        "from accelerate.utils.modeling import infer_auto_device_map\n",
        "from tqdm.auto import tqdm\n",
        "import ctypes\n",
        "libc = ctypes.CDLL(\"libc.so.6\")\n",
        "tqdm.pandas()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.options.display.max_rows = 999\n",
        "pd.options.display.max_colwidth = 99"
      ],
      "metadata": {
        "id": "ZWo11-e_0SCd"
      },
      "id": "ZWo11-e_0SCd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "0c15540f",
      "metadata": {
        "papermill": {
          "duration": 0.004594,
          "end_time": "2024-01-21T13:31:21.634008",
          "exception": false,
          "start_time": "2024-01-21T13:31:21.629414",
          "status": "completed"
        },
        "tags": [],
        "id": "0c15540f"
      },
      "source": [
        "## TPU Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df3623af",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-21T13:31:21.644852Z",
          "iopub.status.busy": "2024-01-21T13:31:21.644417Z",
          "iopub.status.idle": "2024-01-21T13:31:22.415437Z",
          "shell.execute_reply": "2024-01-21T13:31:22.414564Z"
        },
        "papermill": {
          "duration": 0.779031,
          "end_time": "2024-01-21T13:31:22.417418",
          "exception": false,
          "start_time": "2024-01-21T13:31:21.638387",
          "status": "completed"
        },
        "tags": [],
        "id": "df3623af"
      },
      "outputs": [],
      "source": [
        "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\n",
        "from transformers import (\n",
        "    LlamaModel, LlamaConfig, LlamaForSequenceClassification, BitsAndBytesConfig,\n",
        "    AutoTokenizer, AutoModelForCausalLM, AutoConfig, AutoModelForSequenceClassification,\n",
        "    DataCollatorWithPadding, MistralForSequenceClassification\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch_xla.debug.profiler as xp\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "import torch_xla.test.test_utils as test_utils\n",
        "import torch_xla.experimental.xla_sharding as xs\n",
        "import torch_xla.runtime as xr\n",
        "xr.use_spmd()\n",
        "assert xr.is_spmd() == True"
      ],
      "metadata": {
        "id": "C9T2GkjR0ZMg"
      },
      "id": "C9T2GkjR0ZMg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch_xla.experimental.xla_sharding as xs\n",
        "from torch_xla.experimental.xla_sharded_tensor import XLAShardedTensor\n",
        "from torch_xla.experimental.xla_sharding import Mesh\n",
        "from spmd_util import partition_module"
      ],
      "metadata": {
        "id": "JCvRK4yA0X12"
      },
      "id": "JCvRK4yA0X12",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7811678d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-21T13:31:22.437428Z",
          "iopub.status.busy": "2024-01-21T13:31:22.437131Z",
          "iopub.status.idle": "2024-01-21T13:31:22.444464Z",
          "shell.execute_reply": "2024-01-21T13:31:22.443747Z"
        },
        "papermill": {
          "duration": 0.014527,
          "end_time": "2024-01-21T13:31:22.446039",
          "exception": false,
          "start_time": "2024-01-21T13:31:22.431512",
          "status": "completed"
        },
        "tags": [],
        "id": "7811678d"
      },
      "outputs": [],
      "source": [
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "SEED = 666\n",
        "seed_everything(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8b78df3",
      "metadata": {
        "papermill": {
          "duration": 0.004322,
          "end_time": "2024-01-21T13:31:22.455133",
          "exception": false,
          "start_time": "2024-01-21T13:31:22.450811",
          "status": "completed"
        },
        "tags": [],
        "id": "e8b78df3"
      },
      "source": [
        "# Load training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eff31256",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-21T13:31:22.465505Z",
          "iopub.status.busy": "2024-01-21T13:31:22.465255Z",
          "iopub.status.idle": "2024-01-21T13:31:22.471362Z",
          "shell.execute_reply": "2024-01-21T13:31:22.470625Z"
        },
        "papermill": {
          "duration": 0.013155,
          "end_time": "2024-01-21T13:31:22.472819",
          "exception": false,
          "start_time": "2024-01-21T13:31:22.459664",
          "status": "completed"
        },
        "tags": [],
        "id": "eff31256"
      },
      "outputs": [],
      "source": [
        "def cv_split(train_data):\n",
        "    N_FOLD = 5\n",
        "    skf = StratifiedKFold(n_splits=N_FOLD, shuffle=True, random_state=SEED)\n",
        "    X = train_data.loc[:, train_data.columns != \"label\"]\n",
        "    y = train_data.loc[:, train_data.columns == \"label\"]\n",
        "\n",
        "    for fold, (train_index, valid_index) in enumerate(skf.split(X, y)):\n",
        "        train_data.loc[valid_index, \"fold\"] = fold\n",
        "\n",
        "    print(train_data.groupby(\"fold\")[\"label\"].value_counts())\n",
        "    return train_data\n",
        "\n",
        "def load_train_data():\n",
        "    train_data = pd.read_csv('df_all.csv')\n",
        "    train_data = train_data[[\"text\", \"labels\"]]\n",
        "    train_data = train_data.rename(columns={'labels':'label'})\n",
        "    train_data.reset_index(inplace=True, drop=True)\n",
        "\n",
        "    print(f\"Train data value counts: {train_data.value_counts('label')}\")\n",
        "    return train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3968d7ce",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-21T13:31:22.483145Z",
          "iopub.status.busy": "2024-01-21T13:31:22.482910Z",
          "iopub.status.idle": "2024-01-21T13:31:27.276374Z",
          "shell.execute_reply": "2024-01-21T13:31:27.275543Z"
        },
        "papermill": {
          "duration": 4.80087,
          "end_time": "2024-01-21T13:31:27.278028",
          "exception": false,
          "start_time": "2024-01-21T13:31:22.477158",
          "status": "completed"
        },
        "tags": [],
        "id": "3968d7ce",
        "outputId": "4591256f-0131-4cea-edce-327e98b1249a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train data value counts: label\n",
            "0    53958\n",
            "1    36797\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Cars. Cars have been around since they became famous in the 1900s, when Henry Ford created and ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Transportation is a large necessity in most countries worldwide. With no doubt, cars, buses, an...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"America's love affair with it's vehicles seems to be cooling\" says Elisabeth rosenthal. To und...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How often do you ride in a car? Do you drive a one or any other motor vehicle to work? The stor...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Cars are a wonderful thing. They are perhaps one of the worlds greatest advancements and techno...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                 text  \\\n",
              "0  Cars. Cars have been around since they became famous in the 1900s, when Henry Ford created and ...   \n",
              "1  Transportation is a large necessity in most countries worldwide. With no doubt, cars, buses, an...   \n",
              "2  \"America's love affair with it's vehicles seems to be cooling\" says Elisabeth rosenthal. To und...   \n",
              "3  How often do you ride in a car? Do you drive a one or any other motor vehicle to work? The stor...   \n",
              "4  Cars are a wonderful thing. They are perhaps one of the worlds greatest advancements and techno...   \n",
              "\n",
              "   label  \n",
              "0      0  \n",
              "1      0  \n",
              "2      0  \n",
              "3      0  \n",
              "4      0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_data = load_train_data()\n",
        "display(train_data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aaefc99f",
      "metadata": {
        "papermill": {
          "duration": 0.004924,
          "end_time": "2024-01-21T13:31:27.313785",
          "exception": false,
          "start_time": "2024-01-21T13:31:27.308861",
          "status": "completed"
        },
        "tags": [],
        "id": "aaefc99f"
      },
      "source": [
        "# Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9297e860",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-21T13:31:27.325333Z",
          "iopub.status.busy": "2024-01-21T13:31:27.325069Z",
          "iopub.status.idle": "2024-01-21T13:31:27.360726Z",
          "shell.execute_reply": "2024-01-21T13:31:27.359906Z"
        },
        "papermill": {
          "duration": 0.044076,
          "end_time": "2024-01-21T13:31:27.362404",
          "exception": false,
          "start_time": "2024-01-21T13:31:27.318328",
          "status": "completed"
        },
        "tags": [],
        "id": "9297e860"
      },
      "outputs": [],
      "source": [
        "class TrainModelTPU():\n",
        "    def __init__(self, model, train_data, **params):\n",
        "        # Create train and valid dataset\n",
        "        self.train_df, self.valid_df = train_test_split(train_data, test_size=0.0005,\n",
        "                                                        stratify=train_data['label'],\n",
        "                                                        random_state=SEED)\n",
        "        self.LR = params['lr']\n",
        "        self.R = params['r']\n",
        "        self.NUM_EPOCHS = params['num_epochs']\n",
        "\n",
        "        self.NUM_LABELS = 1\n",
        "        self.MAX_LENGTH = params['max_length']\n",
        "        self.BATCH_SIZE = 16\n",
        "        self.DEVICE = xm.xla_device()\n",
        "        self.NUM_WARMUP_STEPS = 0\n",
        "        self.GRADIENT_ACCUMULATION_STEPS = 2\n",
        "\n",
        "        self.MODEL = model\n",
        "\n",
        "    # Load pretrained LLM and tokenizer\n",
        "    def load_model(self):\n",
        "        if \"mistral_7b\" == self.MODEL:\n",
        "            MODEL_PATH = \"/mistral/pytorch/7b-v0.1-hf/1\"\n",
        "        if \"llama-2_7b\" == self.MODEL:\n",
        "            MDEL_PATH = \"/llama-2/pytorch/7b-hf/1\"\n",
        "\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, use_fast=False)\n",
        "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "\n",
        "        base_model = LlamaForSequenceClassification.from_pretrained(MODEL_PATH,\n",
        "                                                                num_labels=self.NUM_LABELS,\n",
        "                                                                torch_dtype=torch.bfloat16)\n",
        "\n",
        "        base_model.config.pretraining_tp = 1\n",
        "\n",
        "        base_model.config.pad_token_id = self.tokenizer.pad_token_id\n",
        "\n",
        "\n",
        "        # LoRa\n",
        "        peft_config = LoraConfig(\n",
        "            r=self.R,\n",
        "            lora_dropout=0.001,\n",
        "            bias='none',\n",
        "            inference_mode=False,\n",
        "            task_type=TaskType.SEQ_CLS,\n",
        "            target_modules=['o_proj', 'v_proj'],\n",
        "        )\n",
        "        self.model = get_peft_model(base_model, peft_config)\n",
        "        self.model.print_trainable_parameters()\n",
        "        print(\"Complete loading pretrained LLM model\")\n",
        "\n",
        "    def save_model(self):\n",
        "        self.model = self.model.cpu()\n",
        "        SAVE_PATH = f'{self.MODEL}/{self.MODEL}_TPU/'\n",
        "        self.model.save_pretrained(SAVE_PATH)\n",
        "        # Save tokenizer for inference\n",
        "        self.tokenizer.save_pretrained(SAVE_PATH)\n",
        "        torch.save(dict([(k,v) for k, v in self.model.named_parameters() if v.requires_grad]),\n",
        "                   SAVE_PATH + 'model_weights.pth')\n",
        "        print(f\"Save the model and tokenizers to {SAVE_PATH}\")\n",
        "\n",
        "    def display_model_layers(self):\n",
        "        # Dispaly trainable layers for verification\n",
        "        trainable_layers = []\n",
        "        n_trainable_params = 0\n",
        "        for name, param in self.model.named_parameters():\n",
        "            n_params = int(torch.prod(torch.tensor(param.shape)))\n",
        "            if param.requires_grad:\n",
        "                trainable_layers.append({\n",
        "                    '#param': n_params,\n",
        "                    'name': name,\n",
        "                    'dtype': param.data.dtype,\n",
        "                    'params': param\n",
        "                })\n",
        "                n_trainable_params += n_params\n",
        "\n",
        "        display(pd.DataFrame(trainable_layers))\n",
        "        print(f\"Number of trainable parameters: {n_trainable_params:,} \"\n",
        "              f\"Number of trainable layers: {len(trainable_layers)}\")\n",
        "\n",
        "    def create_optimizer_scheduler(self, STEPS_PER_EPOCH):\n",
        "        # Optimizer (Adam)\n",
        "        optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.LR, weight_decay=0.01)\n",
        "        # Cosine Learning Rate\n",
        "        lr_scheduler = transformers.get_cosine_schedule_with_warmup(\n",
        "                                    optimizer=optimizer,\n",
        "                                    num_warmup_steps=self.NUM_WARMUP_STEPS,\n",
        "                                    num_training_steps=STEPS_PER_EPOCH * self.NUM_EPOCHS)\n",
        "        for state in optimizer.state.values():\n",
        "            for k, v in state.items():\n",
        "                if isinstance(v, torch.Tensor) and state[k].dtype is not torch.float32:\n",
        "                    state[v] = v.to(dtype=torch.float32)\n",
        "        print(\"Complete creating optimizer and lr scheduler\")\n",
        "        print(\"optimizer\", optimizer)\n",
        "        print(\"lr_scheduler\", lr_scheduler)\n",
        "        return optimizer, lr_scheduler\n",
        "\n",
        "    def partition_mesh(self):\n",
        "        # Number of TPU Nodes\n",
        "        num_devices = xr.global_runtime_device_count()\n",
        "        mesh_shape = (1, num_devices, 1)\n",
        "        print(f'Number_DEVICES: {num_devices}')\n",
        "        device_ids = np.array(range(num_devices))\n",
        "        mesh = Mesh(device_ids, mesh_shape, ('dp', 'fsdp', 'mp'))\n",
        "        partition_module(self.model, mesh)\n",
        "        return num_devices, mesh\n",
        "\n",
        "     # Create a training dataset\n",
        "    def create_dataset(self, N_SAMPLES, INPUT_IDS, ATTENTION_MASKS, GENERATED, mesh):\n",
        "        IDXS = np.arange(N_SAMPLES-(N_SAMPLES%self.BATCH_SIZE))\n",
        "        while True:\n",
        "            # Shuffle Indices\n",
        "            np.random.shuffle(IDXS)\n",
        "            for idxs in IDXS.reshape(-1, self.BATCH_SIZE):\n",
        "                input_ids = torch.tensor(INPUT_IDS[idxs]).to(self.DEVICE)\n",
        "                attention_mask = torch.tensor(ATTENTION_MASKS[idxs]).to(self.DEVICE)\n",
        "                labels = torch.tensor(GENERATED[idxs]).to(self.DEVICE)\n",
        "                # Shard Over TPU Nodes\n",
        "                xs.mark_sharding(input_ids, mesh, (0, 1))\n",
        "                xs.mark_sharding(attention_mask, mesh, (0, 1))\n",
        "                xs.mark_sharding(labels, mesh, (0, 1))\n",
        "                yield input_ids, attention_mask, labels\n",
        "\n",
        "    # Validate the model\n",
        "    def valid_model(self):\n",
        "        num_devices, mesh = self.partition_mesh()\n",
        "        N_SAMPLES = len(self.valid_df)\n",
        "        print(f\"Start validating the model with number of sample {N_SAMPLES}\")\n",
        "        # Tokenize Data\n",
        "        tokens = self.tokenizer(self.valid_df['text'].tolist(),\n",
        "                                padding='max_length',\n",
        "                                max_length=self.MAX_LENGTH,\n",
        "                                truncation=True,\n",
        "                                return_tensors='np',\n",
        "                           )\n",
        "\n",
        "        INPUT_IDS = tokens['input_ids']\n",
        "        # Attention Masks\n",
        "        ATTENTION_MASKS = tokens['attention_mask']\n",
        "        # Generated By AI Label of Texts\n",
        "        GENERATED = self.valid_df['label'].values.reshape(-1,1).astype(np.float32)\n",
        "        # Create a valid dataset\n",
        "        VALID_DATASET = self.create_dataset(N_SAMPLES, INPUT_IDS, ATTENTION_MASKS, GENERATED, mesh)\n",
        "\n",
        "        # Compute the number of batches\n",
        "        IDXS = np.array_split(np.arange(N_SAMPLES), max(1, N_SAMPLES // self.BATCH_SIZE))\n",
        "        LOSS_FN = torch.nn.BCEWithLogitsLoss().to(dtype=torch.float32)\n",
        "        METRICS = {'loss': [],\n",
        "                   'auc': {'y_true': [], 'y_pred': []} }\n",
        "        STEPS = N_SAMPLES // self.BATCH_SIZE\n",
        "        for step in tqdm(range(STEPS)):\n",
        "            # Enable inference mode using `no_grad`\n",
        "            with torch.no_grad():\n",
        "                # Get Batch\n",
        "                input_ids, attention_mask, labels = next(VALID_DATASET)\n",
        "                 # Forward Pass\n",
        "                outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                # Logits Float32\n",
        "                logits = outputs.logits.to(dtype=torch.float32)\n",
        "                # Backward Pass\n",
        "                loss = LOSS_FN(logits, labels)\n",
        "                METRICS['loss'].append(float(loss))\n",
        "                METRICS['auc']['y_true'] += labels.squeeze().tolist()\n",
        "                METRICS['auc']['y_pred'] += logits.sigmoid().tolist()\n",
        "        loss = np.mean(METRICS['loss'])\n",
        "        roc_auc = sklearn.metrics.roc_auc_score(METRICS['auc']['y_true'], METRICS['auc']['y_pred'])\n",
        "        # Compute and display the validation results\n",
        "        print(f\"Number of validation data {len(self.valid_df)}\\n\"\n",
        "              f\"µ_loss: {loss: .3f}\\n\"\n",
        "              f\"µ_auc: {roc_auc:.3f}\")\n",
        "        return {\"eval_loss\": loss, \"eval_roc_auc\": roc_auc}\n",
        "\n",
        "    # Train the model by the fold data\n",
        "    def train_model(self):\n",
        "        num_devices, mesh = self.partition_mesh()\n",
        "        print(f'Number_DEVICES: {num_devices}')\n",
        "        print(f\"Total number of train data = {len(self.train_df)}\")\n",
        "\n",
        "        train_df = self.train_df[['text', 'label']]\n",
        "        train_df['text'] = train_df['text'].map(lambda text: pre_processing_text(text))\n",
        "        N_SAMPLES = len(train_df)\n",
        "        STEPS_PER_EPOCH = N_SAMPLES // self.BATCH_SIZE\n",
        "        print(f'BATCH_SIZE: {self.BATCH_SIZE}, N_SAMPLES: {N_SAMPLES}, STEPS_PER_EPOCH: {STEPS_PER_EPOCH}')\n",
        "\n",
        "        tokens = self.tokenizer(train_df['text'].tolist(),\n",
        "                                padding='max_length',\n",
        "                                max_length=self.MAX_LENGTH,\n",
        "                                truncation=True,\n",
        "                                return_tensors='np',\n",
        "                                )\n",
        "        INPUT_IDS = tokens['input_ids']\n",
        "        # Attention Masks\n",
        "        ATTENTION_MASKS = tokens['attention_mask']\n",
        "        GENERATED = train_df['label'].values.reshape(-1,1).astype(np.float32)\n",
        "        print(f'INPUT_IDS shape: {INPUT_IDS.shape}\\n'\n",
        "              f'ATTENTION_MASKS shape: {ATTENTION_MASKS.shape}\\n'\n",
        "              f'GENERATED shape: {GENERATED.shape}')\n",
        "\n",
        "        TRAIN_DATASET = self.create_dataset(N_SAMPLES, INPUT_IDS, ATTENTION_MASKS, GENERATED, mesh)\n",
        "\n",
        "        optimizer, lr_scheduler = self.create_optimizer_scheduler(STEPS_PER_EPOCH)\n",
        "\n",
        "        self.model.train()\n",
        "        LOSS_FN = torch.nn.BCEWithLogitsLoss().to(dtype=torch.float32)\n",
        "        eval_scores = []\n",
        "        # Training loop goes through each epoch\n",
        "        for epoch in tqdm(range(self.NUM_EPOCHS)):\n",
        "            start = time.time()\n",
        "            METRICS = {'loss': [],\n",
        "                       'auc': {'y_true': [], 'y_pred': []} }\n",
        "            for step in range(STEPS_PER_EPOCH):\n",
        "                # Zero Out Gradients\n",
        "                optimizer.zero_grad()\n",
        "                # Get Batch\n",
        "                input_ids, attention_mask, labels = next(TRAIN_DATASET)\n",
        "                # Forward\n",
        "                outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                # Logits Float32\n",
        "                logits = outputs.logits.to(dtype=torch.float32)\n",
        "                # Backward\n",
        "                loss = LOSS_FN(logits, labels)\n",
        "                # backward propagation\n",
        "                loss.backward()\n",
        "                if (step + 1) % self.GRADIENT_ACCUMULATION_STEPS == 0:\n",
        "                    optimizer.step()\n",
        "                    xm.mark_step()\n",
        "                    lr_scheduler.step()\n",
        "                METRICS['loss'].append(float(loss))\n",
        "                METRICS['auc']['y_true'] += labels.squeeze().tolist()\n",
        "                METRICS['auc']['y_pred'] += logits.sigmoid().tolist()\n",
        "                if np.unique(METRICS['auc']['y_true']).size == 2:\n",
        "                    metrics = 'µ_loss: {:.3f}'.format(np.mean(METRICS['loss']))\n",
        "                    metrics += ', step_loss: {:.3f}'.format(METRICS['loss'][-1])\n",
        "                    metrics += ', µ_auc: {:.3f}'.format(\n",
        "                        sklearn.metrics.roc_auc_score(METRICS['auc']['y_true'], METRICS['auc']['y_pred'])\n",
        "                    )\n",
        "\n",
        "                    lr = optimizer.param_groups[0]['lr']\n",
        "                    print('\\r'*100, f'{epoch+1:02}/{self.NUM_EPOCHS:02} | {step+1:04}/{STEPS_PER_EPOCH} lr: {lr:.2E}, {metrics}', end='')\n",
        "            avg_loss = np.mean(METRICS['loss'])\n",
        "            roc_auc_score = sklearn.metrics.roc_auc_score(METRICS['auc']['y_true'],\n",
        "                                                          METRICS['auc']['y_pred'])\n",
        "            print(f'\\n=== Finish Training Epoch {epoch} with average loss {avg_loss: .5f} '\n",
        "                  f'ROC Accuracy Score {roc_auc_score:.5f} ===')\n",
        "            # Validate the model at the end of epochs\n",
        "            result = self.valid_model()\n",
        "            eval_roc_auc = float(result['eval_roc_auc'])\n",
        "            print(f'\\n=== Finish Validating the model with evaluated ROC Accuracy Score {eval_roc_auc:.5f}'\n",
        "                  f'\\n Total running time = {time.time() -  start: .1f} seconds ===')\n",
        "            eval_scores.append(eval_roc_auc)\n",
        "        return np.mean(eval_scores)\n",
        "\n",
        "    # Clear the memory\n",
        "    def clear_memory(self):\n",
        "        del self.model, self.tokenizer\n",
        "        libc.malloc_trim(0)\n",
        "        gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56b1789e",
      "metadata": {
        "papermill": {
          "duration": 0.004903,
          "end_time": "2024-01-21T13:31:27.371837",
          "exception": false,
          "start_time": "2024-01-21T13:31:27.366934",
          "status": "completed"
        },
        "tags": [],
        "id": "56b1789e"
      },
      "source": [
        "# Use Optuna to find the optimal hyper-parameters\n",
        "Train and Save the model with best parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2ca6097",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-21T13:31:27.382852Z",
          "iopub.status.busy": "2024-01-21T13:31:27.382573Z",
          "iopub.status.idle": "2024-01-21T13:31:27.389989Z",
          "shell.execute_reply": "2024-01-21T13:31:27.389164Z"
        },
        "papermill": {
          "duration": 0.015327,
          "end_time": "2024-01-21T13:31:27.391698",
          "exception": false,
          "start_time": "2024-01-21T13:31:27.376371",
          "status": "completed"
        },
        "tags": [],
        "id": "f2ca6097",
        "outputId": "1b27ece9-603b-4f67-a960-0e97529d02b3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Cars. Cars have been around since they became famous in the 1900s, when Henry Ford created and ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Transportation is a large necessity in most countries worldwide. With no doubt, cars, buses, an...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"America's love affair with it's vehicles seems to be cooling\" says Elisabeth rosenthal. To und...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                 text  \\\n",
              "0  Cars. Cars have been around since they became famous in the 1900s, when Henry Ford created and ...   \n",
              "1  Transportation is a large necessity in most countries worldwide. With no doubt, cars, buses, an...   \n",
              "2  \"America's love affair with it's vehicles seems to be cooling\" says Elisabeth rosenthal. To und...   \n",
              "\n",
              "   label  \n",
              "0      0  \n",
              "1      0  \n",
              "2      0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(train_data.head(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c62157ac",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-21T13:31:27.403081Z",
          "iopub.status.busy": "2024-01-21T13:31:27.402606Z",
          "iopub.status.idle": "2024-01-21T13:31:27.409447Z",
          "shell.execute_reply": "2024-01-21T13:31:27.408702Z"
        },
        "papermill": {
          "duration": 0.014848,
          "end_time": "2024-01-21T13:31:27.411206",
          "exception": false,
          "start_time": "2024-01-21T13:31:27.396358",
          "status": "completed"
        },
        "tags": [],
        "id": "c62157ac"
      },
      "outputs": [],
      "source": [
        "# Start optuna study to hyper-parameter tuning\n",
        "best_score = -1.0\n",
        "def objective(trial, model_name, train_data):\n",
        "\n",
        "    params = {\n",
        "        'lr': trial.suggest_float('learning_rate', 1e-7, 1e-3, log=True),\n",
        "        'r': 64,\n",
        "        'num_epochs': 1,\n",
        "        'max_length' : 512,\n",
        "    }\n",
        "    trainer = TrainModelTPU(model_name, train_data, **params)\n",
        "    trainer.load_model()\n",
        "    eval_score = trainer.train_model()\n",
        "    # Save the model is the avg score > current best score\n",
        "    global best_score\n",
        "    if eval_score > best_score:\n",
        "        best_score = eval_score\n",
        "        trainer.save_model()\n",
        "    # Clean up\n",
        "    trainer.clear_memory()\n",
        "    del trainer\n",
        "    return eval_score\n",
        "\n",
        "def train_model_with_optuna(model_name, train_data):\n",
        "\n",
        "    study_name = f\"{model_name}_study\"\n",
        "    study_file = f\"{study_name}.db\"\n",
        "    # Delete the study file if exits\n",
        "    if os.path.isfile(study_file):\n",
        "        os.remove(f'{study_file}')\n",
        "\n",
        "    study = optuna.create_study(direction=\"maximize\", study_name=study_name,\n",
        "                                storage=\"sqlite:///\" + f\"{study_file}\",\n",
        "                                load_if_exists=False)\n",
        "\n",
        "    study.optimize(lambda trial: objective(trial, model_name, train_data),\n",
        "                   timeout=600, n_jobs=1, n_trials=10,\n",
        "                   show_progress_bar=True, gc_after_trial=True)\n",
        "    print(f\"Best parameters: {study.best_params}\")\n",
        "    params = study.best_params"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "872a61bf",
      "metadata": {
        "papermill": {
          "duration": 0.029734,
          "end_time": "2024-01-21T13:31:27.445734",
          "exception": false,
          "start_time": "2024-01-21T13:31:27.416000",
          "status": "completed"
        },
        "tags": [],
        "id": "872a61bf"
      },
      "source": [
        "# Train the model with best parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "696c0a8a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-21T13:31:27.456864Z",
          "iopub.status.busy": "2024-01-21T13:31:27.456608Z",
          "iopub.status.idle": "2024-01-21T13:31:27.461330Z",
          "shell.execute_reply": "2024-01-21T13:31:27.460567Z"
        },
        "papermill": {
          "duration": 0.01225,
          "end_time": "2024-01-21T13:31:27.462906",
          "exception": false,
          "start_time": "2024-01-21T13:31:27.450656",
          "status": "completed"
        },
        "tags": [],
        "id": "696c0a8a"
      },
      "outputs": [],
      "source": [
        "def train_model(model_name, train_data):\n",
        "    # Parameters\n",
        "    params = {\n",
        "        'lr': 5e-5,\n",
        "        'r': 64,\n",
        "        'num_epochs': 2,\n",
        "        'max_length': 512\n",
        "    }\n",
        "    trainer = TrainModelTPU(model_name, train_data, **params)\n",
        "    trainer.load_model()\n",
        "    eval_score = trainer.train_model()\n",
        "    trainer.save_model()\n",
        "    # Clean up\n",
        "    trainer.clear_memory()\n",
        "    del trainer\n",
        "    print(f\"=== Finish training the model {model_name} with score = {eval_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd2b71a4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-21T13:31:27.473940Z",
          "iopub.status.busy": "2024-01-21T13:31:27.473691Z",
          "iopub.status.idle": "2024-01-21T21:26:55.019513Z",
          "shell.execute_reply": "2024-01-21T21:26:55.018362Z"
        },
        "papermill": {
          "duration": 28527.55396,
          "end_time": "2024-01-21T21:26:55.021481",
          "exception": false,
          "start_time": "2024-01-21T13:31:27.467521",
          "status": "completed"
        },
        "scrolled": true,
        "tags": [],
        "id": "dd2b71a4"
      },
      "outputs": [],
      "source": [
        "model_name = \"mistral_7b\"\n",
        "train_model(model_name, train_data)"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "tpu1vmV38",
      "dataSources": [
        {
          "databundleVersionId": 7516023,
          "sourceId": 61542,
          "sourceType": "competition"
        },
        {
          "datasetId": 2663421,
          "sourceId": 4620664,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 3863727,
          "sourceId": 6703755,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 3972872,
          "sourceId": 6921012,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4005256,
          "sourceId": 6977472,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4287904,
          "sourceId": 7378735,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4328487,
          "sourceId": 7437171,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4059536,
          "sourceId": 7443031,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4049286,
          "sourceId": 7443707,
          "sourceType": "datasetVersion"
        },
        {
          "modelInstanceId": 3090,
          "sourceId": 4295,
          "sourceType": "modelInstanceVersion"
        },
        {
          "modelInstanceId": 3899,
          "sourceId": 5111,
          "sourceType": "modelInstanceVersion"
        }
      ],
      "dockerImageVersionId": 30581,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 28632.630084,
      "end_time": "2024-01-21T21:27:11.703642",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-01-21T13:29:59.073558",
      "version": "2.5.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}